version: '3.4'

services:
  proxy:
    image: nginx:1.21.0-alpine
    container_name: proxy
    volumes:
      - .proxy/default.conf:/etc/nginx/templates/default.conf.template
    ports:
      - $PROXY_PORT:80
    depends_on:
      - auth-service
      - employee-service
      - time-record-service
    networks:
      - timeclock

  auth-service:
    image: ghcr.io/c-4u/auth-service:latest
    environment:
      KEYCLOAK_BASE_PATH: $KEYCLOAK_BASE_PATH
      KEYCLOAK_REALM: $KEYCLOAK_REALM
      KEYCLOAK_CLIENT_ID: $KEYCLOAK_CLIENT_ID
      KEYCLOAK_CLIENT_SECRET: $KEYCLOAK_CLIENT_SECRET
      KEYCLOAK_AUDIENCE: $KEYCLOAK_AUDIENCE
      ELASTIC_APM_SERVER_URL: $ELASTIC_APM_SERVER_URL
      ELASTIC_APM_SERVICE_NAME: auth-service
    volumes:
      - ../auth-service:/go/src/
    ports:
      - 8088:8080
    depends_on:
      - keycloak
    networks:
      - timeclock
    extra_hosts:
      - 'host.docker.internal:172.17.0.1'

  keycloak:
    image: quay.io/keycloak/keycloak:latest
    environment:
      DB_VENDOR: POSTGRES
      DB_ADDR: keycloakdb
      DB_DATABASE: $KEYCLOAK_DB
      DB_USER: $KEYCLOAK_USERNAME
      DB_SCHEMA: public
      DB_PASSWORD: $KEYCLOAK_PASSWORD
      KEYCLOAK_USER: $KEYCLOAK_USERNAME
      KEYCLOAK_PASSWORD: $KEYCLOAK_PASSWORD
      # Uncomment the line below if you want to specify JDBC parameters. The parameter below is just an example, and it shouldn't be used in production without knowledge. It is highly recommended that you read the PostgreSQL JDBC driver documentation in order to use it.
      #JDBC_PARAMS: "ssl=true"
    ports:
      - 8080:8080
    depends_on:
      - keycloakdb
    networks:
      - timeclock

  keycloakdb:
    image: postgres
    volumes:
      - pgauthdb:/var/lib/postgresql/data
    environment:
      POSTGRES_DB: $KEYCLOAK_DB
      POSTGRES_USER: $KEYCLOAK_USERNAME
      POSTGRES_PASSWORD: $KEYCLOAK_PASSWORD
    networks:
      - timeclock

  time-record-service:
    image: ghcr.io/c-4u/time-record-service:latest
    environment:
      DB_URI: $DB_URI
      DB_NAME: $DB_NAME
      AUTH_SERVICE_ADDR: $AUTH_SERVICE_ADDR
      EMPLOYEE_SERVICE_ADDR: $EMPLOYEE_SERVICE_ADDR
      ELASTIC_APM_SERVER_URL: $ELASTIC_APM_SERVER_URL
      ELASTIC_APM_SERVICE_NAME: time-record-service
    volumes:
      - ../time-record-service:/go/src/
    ports:
      - 8089:8080
    depends_on:
      - trdb
    networks:
      - timeclock
    extra_hosts:
      - 'host.docker.internal:172.17.0.1'

  trdb:
    image: mongo:4.4
    restart: always
    command: mongod --auth
    tty: true
    environment:
      MONGO_INITDB_ROOT_USERNAME: $MONGODB_USERNAME
      MONGO_INITDB_ROOT_PASSWORD: $MONGODB_PASSWORD
      MONGO_INITDB_DATABASE: $DB_NAME
      MONGODB_DATA_DIR: /data/db
      MONDODB_LOG_DIR: /dev/null
    volumes:
      - mgdata:/data/db
    networks:
      - timeclock

  mongo-express:
    image: mongo-express
    tty: true
    environment:
      ME_CONFIG_BASICAUTH_USERNAME: admin
      ME_CONFIG_BASICAUTH_PASSWORD: admin123
      ME_CONFIG_MONGODB_PORT: 27017
      ME_CONFIG_MONGODB_SERVER: trdb
      ME_CONFIG_MONGODB_ADMINUSERNAME: $MONGODB_USERNAME
      ME_CONFIG_MONGODB_ADMINPASSWORD: $MONGODB_PASSWORD
    ports:
      - 8081:8081
    depends_on:
      - trdb
    networks:
      - timeclock

  employee-service:
    image: ghcr.io/c-4u/employee-service:latest
    environment:
      KEYCLOAK_BASE_PATH: $KEYCLOAK_BASE_PATH
      KEYCLOAK_REALM: $KEYCLOAK_REALM
      KEYCLOAK_REALM_ADMIN_USERNAME: $KEYCLOAK_REALM_ADMIN_USERNAME
      KEYCLOAK_REALM_ADMIN_PASSWORD: $KEYCLOAK_REALM_ADMIN_PASSWORD
      AUTH_SERVICE_ADDR: $AUTH_SERVICE_ADDR
      ELASTIC_APM_SERVER_URL: $ELASTIC_APM_SERVER_URL
      ELASTIC_APM_SERVICE_NAME: employee-service
    volumes:
      - ../employee-service:/go/src/
    ports:
      - 8090:8080
    depends_on:
      - keycloak
    networks:
      - timeclock
    extra_hosts:
      - 'host.docker.internal:172.17.0.1'

  # APM
  apm-server:
    image: docker.elastic.co/apm/apm-server:7.12.1
    depends_on:
      - elasticsearch
      - kibana
    cap_add: ['CHOWN', 'DAC_OVERRIDE', 'SETGID', 'SETUID']
    cap_drop: ['ALL']
    networks:
      - timeclock
    environment:
      - ./.elastic/apm-server.yml:/usr/share/apm-server/apm-server.yml
    healthcheck:
      interval: 10s
      retries: 12
      test: curl --write-out 'HTTP %{http_code}' --fail --silent --output /dev/null http://localhost:8200/

  kibana:
    image: 'docker.elastic.co/kibana/kibana:7.12.1'
    ports:
      - 5601:5601
    volumes:
      - ./.elastic/kibana.yml:/usr/share/kibana/config/kibana.yml
    depends_on:
      - elasticsearch
    networks:
      - timeclock
    healthcheck:
      interval: 10s
      retries: 20
      test: curl --write-out 'HTTP %{http_code}' --fail --silent --output /dev/null http://localhost:5601/api/status

  elasticsearch:
    image: 'docker.elastic.co/elasticsearch/elasticsearch:7.12.1'
    volumes:
      - ./.elastic/elasticsearch.yml:/usr/share/elasticsearch/config/elasticsearch.yml
      #   - ./.elastic/elasticsearch-ik-plugin:/usr/share/elasticsearch/plugins/ik
      - esdata:/usr/share/elasticsearch/data
    environment:
      - 'ES_JAVA_OPTS=-Xms512m -Xmx512m' ## setting jvm heap memory limits, based on the type of nodes (master, data, etc.), you can tweak this to optimize resource usage vs. performance
      - node.name=es-master ## node name needs to be unique, so setting it in env vars
    ulimits:
      memlock:
        soft: -1
        hard: -1
    networks:
      - timeclock
    healthcheck:
      interval: 20s
      retries: 10
      test: curl -s http://localhost:9200/_cluster/health | grep -vq '"status":"red"'

volumes:
  esdata:
    driver: local
  pgauthdb:
    driver: local
  mgdata:
    driver: local

networks:
  timeclock:
    driver: bridge
